{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OBTENIR LE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genre</th>\n",
       "      <th>Taille(cm)</th>\n",
       "      <th>Poids(kg)</th>\n",
       "      <th>Pointure(cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>masculin</td>\n",
       "      <td>182</td>\n",
       "      <td>81.6</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>masculin</td>\n",
       "      <td>180</td>\n",
       "      <td>86.2</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>masculin</td>\n",
       "      <td>170</td>\n",
       "      <td>77.1</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>masculin</td>\n",
       "      <td>180</td>\n",
       "      <td>74.8</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>féminin</td>\n",
       "      <td>152</td>\n",
       "      <td>45.4</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>féminin</td>\n",
       "      <td>168</td>\n",
       "      <td>68.0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>féminin</td>\n",
       "      <td>165</td>\n",
       "      <td>59.0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>féminin</td>\n",
       "      <td>175</td>\n",
       "      <td>68.0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Genre  Taille(cm)  Poids(kg)  Pointure(cm)\n",
       "0  masculin         182       81.6            30\n",
       "1  masculin         180       86.2            28\n",
       "2  masculin         170       77.1            30\n",
       "3  masculin         180       74.8            25\n",
       "4   féminin         152       45.4            15\n",
       "5   féminin         168       68.0            20\n",
       "6   féminin         165       59.0            18\n",
       "7   féminin         175       68.0            23"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('pointure.data')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRE-TRAITEMENT DES DONNÉES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 0 0 0 0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genre</th>\n",
       "      <th>Taille(cm)</th>\n",
       "      <th>Poids(kg)</th>\n",
       "      <th>Pointure(cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>182</td>\n",
       "      <td>81.6</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>180</td>\n",
       "      <td>86.2</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>170</td>\n",
       "      <td>77.1</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>180</td>\n",
       "      <td>74.8</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>152</td>\n",
       "      <td>45.4</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>168</td>\n",
       "      <td>68.0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>165</td>\n",
       "      <td>59.0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>175</td>\n",
       "      <td>68.0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Genre  Taille(cm)  Poids(kg)  Pointure(cm)\n",
       "0      1         182       81.6            30\n",
       "1      1         180       86.2            28\n",
       "2      1         170       77.1            30\n",
       "3      1         180       74.8            25\n",
       "4      0         152       45.4            15\n",
       "5      0         168       68.0            20\n",
       "6      0         165       59.0            18\n",
       "7      0         175       68.0            23"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "input_classes = ['masculin','féminin']\n",
    "label_encoder.fit(input_classes)\n",
    "\n",
    "# transformer un ensemble de classes\n",
    "encoded_labels = label_encoder.transform(df['Genre'])\n",
    "print(encoded_labels)\n",
    "df['Genre'] = encoded_labels\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEFINIR LES FEATURES\n",
    "# SEPARER LE DATASET EN TRAIN ET TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, lambda df: [1, 2, 3]]\n",
    "y = df.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#decomposer les donnees predicteurs en training/testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 3) (2, 3) (6,) (2,)\n"
     ]
    }
   ],
   "source": [
    "print (X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FAIRE APPRENDRE LE MODELE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.naive_bayes import GaussianNB\n",
    "#gnb = GaussianNB()\n",
    "#gnb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVALUATION SUR LE TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_naive_bayes1 = gnb.predict(X_train)\n",
    "#print(\"Number of mislabeled points out of a total 0%d points : 0%d\" % (X_train.shape[0],(y_train != y_naive_bayes1).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import metrics\n",
    "# accuracy = metrics.accuracy_score(y_train, y_naive_bayes1)\n",
    "# print(\"Accuracy du modele Naive Bayes predit: \" + str(accuracy))\n",
    "\n",
    "\n",
    "# recall_score = metrics.recall_score(y_train, y_naive_bayes1)\n",
    "# print(\"recall score du modele Naive Bayes predit: \" + str(recall_score))\n",
    "\n",
    "# f1_score = metrics.f1_score(y_train, y_naive_bayes1)\n",
    "# print(\"F1 score du modele Naive Bayes predit: \" + str(f1_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVALUATION SUR LE TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_naive_bayes2 = gnb.predict(X_test)\n",
    "# print(\"Number of mislabeled points out of a total 0%d points : 0%d\" % (X_test.shape[0],(y_test != y_naive_bayes2).sum()))\n",
    "\n",
    "# recall_score = metrics.recall_score(y_test, y_naive_bayes2)\n",
    "# print(\"recall score du modele Naive Bayes predit: \" + str(recall_score))\n",
    "\n",
    "# f1_score = metrics.f1_score(y_test, y_naive_bayes2)\n",
    "# print(\"F1 score du modele Naive Bayes predit: \" + str(f1_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREDICTION SUR UNE OBSERVATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = {'Taille(cm)':[183], 'Poids(kg)':[59], 'Pointure(cm)':[20]}\n",
    "# dfToPredict = pd.DataFrame(data=d) \n",
    "# dfToPredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yPredict = gnb.predict(dfToPredict)\n",
    "# print('La classe predite est : ', yPredict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie MLFLow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn import metrics\n",
    "from urllib.parse import urlparse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment(experiment_name='examen_final_A57_2021')\n",
    "mlflow.set_tracking_uri(\"https://dagshub.com/mkbensmaia/A57_track_metriques.mlflow\")\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 06 points : 00\n",
      "Accuracy du modele Naive Bayes predit: 1.0\n",
      "recall score du modele Naive Bayes predit: 1.0\n",
      "F1 score du modele Naive Bayes predit: 1.0\n",
      "\n",
      "Number of mislabeled points out of a total 02 points : 01\n",
      "recall score du modele Naive Bayes predit: 0.0\n",
      "F1 score du modele Naive Bayes predit: 0.0\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(nested=True):\n",
    "    gnb = GaussianNB()\n",
    "    gnb.fit(X_train, y_train)\n",
    "    \n",
    "    y_naive_bayes1 = gnb.predict(X_train)\n",
    "    print(\"Number of mislabeled points out of a total 0%d points : 0%d\" % (X_train.shape[0],(y_train != y_naive_bayes1).sum()))\n",
    "    \n",
    "    \n",
    "\n",
    "    accuracy = metrics.accuracy_score(y_train, y_naive_bayes1)\n",
    "    print(\"Accuracy du modele Naive Bayes predit: \" + str(accuracy))\n",
    "\n",
    "\n",
    "    recall_score = metrics.recall_score(y_train, y_naive_bayes1)\n",
    "    print(\"recall score du modele Naive Bayes predit: \" + str(recall_score))\n",
    "\n",
    "    f1_score = metrics.f1_score(y_train, y_naive_bayes1)\n",
    "    print(\"F1 score du modele Naive Bayes predit: \" + str(f1_score))\n",
    "    print(\"\")\n",
    "    #######################################################################################################################\n",
    "    # evaluation sur le test\n",
    "    y_naive_bayes2 = gnb.predict(X_test)\n",
    "    print(\"Number of mislabeled points out of a total 0%d points : 0%d\" % (X_test.shape[0],(y_test != y_naive_bayes2).sum()))\n",
    "\n",
    "    recall_score_test_set = metrics.recall_score(y_test, y_naive_bayes2)\n",
    "    print(\"recall score du modele Naive Bayes predit: \" + str(recall_score_test_set))\n",
    "\n",
    "    f1_score_test_set = metrics.f1_score(y_test, y_naive_bayes2)\n",
    "    print(\"F1 score du modele Naive Bayes predit: \" + str(f1_score_test_set))\n",
    "    \n",
    "    \n",
    "    # enregistrer les metrics\n",
    "    mlflow.log_metric(\"recall_score sur test_set\", recall_score_test_set)\n",
    "    mlflow.log_metric(\"f1_score sur test_set\", f1_score_test_set)\n",
    "    \n",
    "    \n",
    "    tracking_url_type_store = urlparse(mlflow.get_tracking_uri()).scheme\n",
    "    \n",
    "    mlflow.sklearn.log_model(gnb, \"modele\")\n",
    "#     mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La classe predite est :  [0]\n"
     ]
    }
   ],
   "source": [
    "d = {'Taille(cm)':[183], 'Poids(kg)':[59], 'Pointure(cm)':[20]}\n",
    "dfToPredict = pd.DataFrame(data=d) \n",
    "dfToPredict\n",
    "\n",
    "yPredict = gnb.predict(dfToPredict)\n",
    "print('La classe predite est : ', yPredict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlflow.log_param(\"prediction\", yPredict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"metrics.txt\", 'w') as outfile:\n",
    "        outfile.write(\"recall_score_test_set:  {} \\n\".format(recall_score_test_set))\n",
    "        outfile.write(\"f1_score_test_set: {}\\n\".format(f1_score_test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
